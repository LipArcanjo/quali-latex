We employ a multi-method research approach, using different methodologies to achieve our 
goals to approach code duplication in some of the Linux subsystems. To validate if the 
ArKanjo tool can find code duplications, we applied two independent methods and performed 
triangulation on the results.

The first method evaluates the proposed tool using an approach from the literature, 
comparing it against the BigCloneBench dataset \citep{bigclonebench}. 
The second method is an empirical analysis of a subset of functions within the 
AMD Display driver that our tool identified as duplicates. After completing these two 
methods, we triangulated the findings to analyze the results comprehensively. 
We chose triangulation because relying solely on the literature-based method has 
limitations and may be unreliable \citep{bigfail, litreview}. 
As a reminder, all research approaches were done using the text similarity method 
as the code duplication detection method of the tool.

Given the validation of the tool’s capabilities, we proceed to understand the viability 
of mitigating the code duplication found by the tool. We conducted an ethnographic study 
using a participant-observation methodology to understand its viability. In this study, 
we aim to mitigate a subset of duplicated functions by refactoring them while interacting 
with the Linux community to gather feedback on our mitigation efforts.

The ethnographic study had two phases. In the first phase, the author explored the process 
of mitigating a code duplication found in the AMD Display driver and sent it as a PATCH to 
interact with the Linux community and get their feedback. In the second phase, we proposed 
to students in the course Free Software Development at the University of São Paulo to mitigate 
the code duplications found by the tool in the IIO subsystem and the AMD Display driver and 
pass the process of sending the mitigations as PATCH.

\section{Evaluation of the Tool by the BigCloneBench dataset}

\label{sec:metbig}

The BigCloneBench dataset \citep{bigclonebench} is a Java code collection containing pairs of code duplications categorized by clone type, as defined in Section \ref{subsec:types}.
%
Following the methodology presented by \citep{tailor}, we sampled 20,000 pairs from each clone type, adding 20,000 non-duplicate pairs as negative samples. We applied the same sampling approach to our tool to ensure a fair evaluation.

Unlike traditional methods, our tool does not distinguish between clone types and identifies duplications at the function level rather than the file level, which is typical in state-of-the-art tools. Therefore, we adapted the metric calculation method for evaluation purposes. Specifically, we considered every pair of functions with a similarity metric equal to or greater than a threshold \(X\) as duplicates and marked the corresponding file pairs. A correctly identified duplication pair counts as accurate for its clone type, while an incorrectly inferred pair is considered incorrect across all clone types. With these definitions, we computed the Recall metric from Section \ref{subsec:codemethods} for each clone type.
%
To understand the impact of varying the similarity threshold, we evaluated our tool using different threshold values: 30\%, 40\%, 50\%, 60\%, 70\%, 80\%, 90\%, and 100\%. We then analyzed and discussed the results.

\section{Evaluation of the Tool by Empirical Analysis}

\label{sec:metemp}

Due to the limitations of the BigCloneBench dataset, as noted by \cite{bigfail}, and its lack of suitability 
for our context (Java dataset vs. C-based Linux kernel), we complemented the BigCloneBench evaluation with 
an empirical study of the tool inferred duplications.

Given the vast number of lines and components in the Linux kernel, analyzing every duplication is impractical. We focused our scope on the AMD Display driver, which, as shown in Figure \ref{fig:relatory_ex}, contains over 20,000 lines of duplicated code at a similarity metric of 100\%.

In this empirical analysis, we randomly sampled function pairs identified by the tool as duplicates. For each similarity threshold \(X\) (30\%, 40\%, 50\%, 60\%, 70\%, 80\%, 90\%, and 100\%), we randomly selected ten function pairs with a similarity close to \(X\), allowing for a 1\% deviation. We implemented the random selection using the tool's source code.

Appendix \ref{app:emp} lists the randomly selected function pairs. We empirically evaluated these pairs to determine if they were duplications, comparing these results with the literature-based method to assess our tool's effectiveness and understand the impact of the minimum similarity parameter.

\section{Ethnographic Study}

\label{sec:meteth}

Ethnography is a recognized qualitative empirical method for understanding people, 
their cultures, and their work practices \citep{bookethno}. It allows researchers 
to gain insights into values, beliefs, and ideas from the perspective of community 
members \citep{ethnosoft}. In our research, refactoring code duplications without 
community interaction would prevent us from understanding whether Linux maintainers 
would accept our approach or identify their concerns. Thus, we will use ethnography, 
positioning ourselves and students as Linux kernel contributors focused on removing 
identified  code duplications.

This section outlines our approach to mitigating code duplication in the Linux kernel 
and describes the ethnographic methodology for engaging with the Linux community. 
Firstly, we present the participant observation research method explored by the author. 
Then, we present the methodology of the non-participant observation analyze of patches 
sent by the students.

\subsection{Participant observation method}
\label{subsec:partmethod}

Given the tool evaluations demonstrating the tool's capabilities of finding duplications, 
we proceeded to understand if the duplications found can be mitigated and the kernel 
subsystem's maintainers' opinions about the duplications and their respective mitigations. 
To accomplish this objective, we proposed a participant-observation experiment, 
where we, people who have never contributed to the Linux kernel, act as contributors to 
the AMD Display driver and collect artifacts of our experience in the process.

We executed the tool in the AMD Display driver codebase. 
We manually analyzed the biggest duplications regarding the number of lines and raised them 
to two duplicated function pairs that we judged interesting to try to mitigate. We have 
chosen to approach the biggest duplications as proof of concept so that we can make 
significant impacts. The two duplicated function pairs chosen are:

\begin{itemize}
\item \textbf{Duplicated function pair 1}
\begin{itemize}
\item Function named \textit{offset\_to\_id} in file \textit{dc/gpio/dcn32/hw\_translate\_dcn32.c}.
\item Function named \textit{offset\_to\_id} in file \textit{dc/gpio/dcn315/hw\_translate\_dcn315.c}.
\end{itemize}
\item \textbf{Duplicated function pair 2}
%\begin{itemize}
\item Function named \textit{phy\_id\_to\_atom} in file \textit{dc/bios/dce110/command\_table\_helper\_dce110.c}.
\item Function named \textit{phy\_id\_to\_atom} in file \textit{dc/bios/dce60/command\_table\_helper\_dce60.c}.
%\end{itemize}
\end{itemize}

Given the two duplicated function pairs, we observed that the files in the functions 
contain multiple other duplications. Thus, we proposed a simple systematic approach 
to mitigate all the functions duplicated in the context, not just the duplicated 
function pairs. 
After we approached the duplications with the systematic approach, for the duplicated 
function pairs that had successfully mitigated the duplication, we sent patches to the 
AMD Display driver email list to validate the mitigations and see the maintainer's opinion 
while documenting the process and our impressions.
The systematic approach is defined below.

\subsubsection{Systematic Approach to Mitigate Code Duplication}
\label{subsubsec:systematic}

In C programming, communication between source files is achieved by creating header files that specify 
libraries \citep{Cbook}. Since the Linux kernel is primarily written in C, we eliminated code duplications 
by consolidating duplicated code into a single library, which would replace instances of 
duplication across the codebase.

For each duplicated function pair, for each function in the pair, we used the \textit{function information} functionality 
(described in Section \ref{subsec:functioncommand}) to locate all duplications of the function in the codebase, 
as it may have been duplicated more times than the two occurrences contained in the duplicated function pair. 
This strategy resulted in a collection of duplicated functions and corresponding code files.

To identify shared code more effectively, we extended this approach to search for other common 
functions across all collection files. We then applied specific refactoring methods to each shared 
function. If the functions were identical across files, we removed the duplicates and created a single 
function in the library. If modifications existed, we applied case-specific refactoring.

\subsection{Non-participant Observation Study with University Students}

A core dynamic of the Free Software Development course at the University of São Paulo is to 
have students make a practical contribution to a free software project. In the first semester of 
2025, the professor teaching the course, who is also the advisor of this work, identified an 
opportunity to leverage the ArKanjo tool within this existing pedagogical structure. As a 
contribution option, the professor proposed that students mitigate code duplications found in the 
Linux kernel. This initiative was driven by the professor as a practical course activity, and 
the author of this thesis was not involved in using the tool to find duplications nor in developing 
the approaches to mitigate them. The tasks were carried out entirely by the course staff 
and the students.

The course had 37 students (25 undergraduate and 12 graduate), who were asked to form groups of 
one to three. To assist students in this task, the professor and teaching assistants prepare multiple 
alternatives for contributing to free software projects, including simpler contributions such as 
updating documentation or fixing code style issues. In this context, two new options related to the 
ArKanjo tool were proposed alongside the others.

For the first ArKanjo-related alternative, a teaching assistant ran the tool on the IIO subsystem, 
creating a list of duplicated function pairs found with a 90\% similarity threshold. The students' 
task was to refactor the code to mitigate these specific duplications and then pass through the process 
of submitting their patches to the IIO maintainers for review.

For the second alternative, students were offered an experience similar to our initial participant 
observation. In this model, the students were responsible for the entire workflow: executing the 
ArKanjo tool on the AMD display driver, independently analyzing the results to identify a duplication 
to fix, creating a patch to mitigate it, and sending the patch to the driver's maintainers.

Of the students who chose to work on the ArKanjo-related tasks, 25 (20 undergraduate and 5 graduate) 
formed 11 groups to pursue the first alternative. One graduate student opted for the second alternative, 
forming a single group. Notably, none of these students had prior experience contributing to the 
Linux kernel, making this their first attempt to submit a patch as newcomers.

The groups were requested to document their experience and approaches to refactoring the 
duplications and the experience of submitting a patch to the Linux kernel in blogs. We analyzed 
these blogs to understand the patterns of refactoring used for mitigating the duplications, the 
experience of sending the patches, and the opinions of the subsystem maintainers on the mitigations.

The teaching assistant and the student who executed the ArKanjo tool to explore duplications were 
asked to answer some questions related to their experience using the tool and what could be improved. 
The survey with the users' answers can be found in Appendix \ref{app:survey}.

In the second stage of the Free Software Development course, we propose that students contribute 
directly to the ArKanjo tool development without help from the tool creator to verify whether the 
tool can be free software to which multiple people can contribute. The students approached the tool’s 
issue, and to our knowledge, they pointed to us in the survey feedback. Three students forming two 
groups worked in direct contributions.
