We employ a multi-method research approach, using different methodologies to achieve our goals
to approach code duplication in some of the Linux subsystems. 
To validate if the Arkanjo tool is capable of finding code duplications, 
applied two independent methods and perform triangulation on the results. 

The first method evaluates the proposed tool using an approach from the literature, 
comparing it against the BigCloneBench dataset \citep{bigclonebench}. 
The second method is an empirical analysis of a subset of functions within the 
AMD Display driver that our tool identified as duplicates. After completing these two 
methods, we triangulated the findings to analyze the results comprehensively. 
We chose triangulation because relying solely on the literature-based method has 
limitations and may not be entirely reliable \citep{bigfail, litreview}. As a reminder, 
all research approches were done using the text similarity method as the 
code dupication method of the tool.

Given the validation of the tool's capabilities, we proceed to undertand the viability 
to mitigate the code duplication finds by the tool. 
To underdand the viability, our first choice is to conduct an ethnographic study using 
a participant-observation methodology. 
In this study, we aim to mitigate a subset of duplicated functions by refactoring them 
while interacting with the Linux community to gather feedback on our mitigation efforts. 

The ethnographic study happened in two phases. 
In the first phase, the author of this research explored the process of mitigating
a code duplication found in the AMD Display Driver and sent it as a PATCH to iteract with the
Linux community and get their feedback. On a second phase, we proposed to students on the 
course Free Software Development at University São Paulo to mitigate the code duplications found 
by the tool in the IIO subsystems and the AMD Display Driver and pass the process of send the mitigations as PATCH.
(DOUBLE CHECK IF THE STUDENTS HAVE SENT THE PATCHES). 

\todo[inline]{I SHOULD mention that the test on the tool were made using the gensim similarity method and not the git method.}

\section{Evaluation of the Tool by the BigCloneBench dataset}

\label{sec:metbig}

The BigCloneBench dataset \citep{bigclonebench} is a Java code collection containing pairs of code duplications categorized by clone type, as defined in Section \ref{subsec:types}.
%
Following the methodology presented by \citep{tailor}, we sampled 20,000 pairs from each clone type, adding 20,000 non-duplicate pairs as negative samples. We applied the same sampling approach to our tool to ensure a fair evaluation.

Unlike traditional methods, our tool does not distinguish between clone types and identifies duplications at the function level rather than the file level, which is typical in state-of-the-art tools. Therefore, we adapted the metric calculation method for evaluation purposes. Specifically, we considered every pair of functions with a similarity metric equal to or greater than a threshold \(X\) as duplicates and marked the corresponding file pairs. A correctly identified duplication pair counts as accurate for its clone type, while an incorrectly inferred pair is considered incorrect across all clone types. With these definitions, we computed the Recall metric from Section \ref{subsec:codemethods} for each clone type.
%
To understand the impact of varying the similarity threshold, we evaluated our tool using different threshold values: 30\%, 40\%, 50\%, 60\%, 70\%, 80\%, 90\%, and 100\%. We then analyzed and discussed the results.

\section{Evaluation of the Tool by Empirical Analysis}

\label{sec:metemp}

\todo[inline]{I just mention the problem, maybe a more explictly mention of the problem here or on the background would be good.}

Due to the limitations of the BigCloneBench dataset, as noted by \cite{bigfail}, and its lack of suitability 
for our context (Java dataset vs. C-based Linux kernel), we complemented the BigCloneBench evaluation with 
an empirical study of the tool inferred duplications.

Given the vast number of lines and components in the Linux kernel, analyzing every duplication is impractical. We focused our scope on the AMD Display driver, which, as shown in Figure \ref{fig:relatory_ex}, contains over 20,000 lines of duplicated code at a similarity metric of 100\%.

In this empirical analysis, we randomly sampled function pairs identified by the tool as duplicates. For each similarity threshold \(X\) (30\%, 40\%, 50\%, 60\%, 70\%, 80\%, 90\%, and 100\%), we randomly selected ten function pairs with a similarity close to \(X\), allowing for a 1\% deviation. We implemented the random selection using the tool's source code.

Appendix \ref{app:emp} lists the randomly selected function pairs. We empirically evaluated these pairs to determine if they were duplications, comparing these results with the literature-based method to assess our tool's effectiveness and understand the impact of the minimum similarity parameter.

\todo[inline]{Take care: Big focus on AMD display driver and the tone of the writing supports the focus. }

\section{Ethnographic Study}

\label{sec:meteth}

Ethnography is a recognized qualitative empirical method for understanding people, 
their cultures, and their work practices \citep{bookethno}. It allows researchers 
to gain insights into values, beliefs, and ideas from the perspective of community 
members \citep{ethnosoft}. In our research, refactoring code duplications without 
community interaction would prevent us from understanding whether Linux maintainers 
would accept our approach or identify their concerns. Thus, we will use ethnography, 
positioning ourselves and students as Linux kernel contributors focused on removing 
identified  code duplications.

This section outlines our approach for mitigating code duplication in the Linux kernel
and describes the ethnographic methodology for engagin with the Linux community. Firstly, 
we present the participant observation research method explored by the author. Then, 
we present the methodolody of the experiment done with the students.

\subsection{Participant observation method}

Given the tool evaluations that demonstrate the tool capabilites of finding duplications, 
we proceeded to undertand if the duplications found are possible to be mitigate and
the kernel subsystem's maintainers opinions about the duplications and their respective mitigations.
To accomplish this objective, we initialy proposed a participant-observation experiment, 
where we, people that have never contribute to the Linux kernel, 
act as contributors to the AMD Display driver and collect artifacts of our experience in the process.

As a first step of this experiment, we executed the tool in the AMD Display driver codebase and 
manually analysed the biggest duplications in terms of number of lines and raised to 
two duplicated function pairs that we judged interesting to try to mitigate. 
We have choose to approach the biggest duplications as a proof of concept that 
we can make significant impacts. The two duplicated function pairs are shown in Table X.

Given the two duplicated function pairs, we observed that the files that the functions exist contains 
multiple other duplications. Thus, we proposed a simple systematic approach to mitigate all the 
functions duplicated in the context and not only the duplicated function pairs. 
The systematic approach is defined below.

After we approached the duplications with the systematic approach. For the duplicated function
pairs that had successfully being mitigate the duplication, we sent patches to the AMD Display driver
maillist to validate the mitigations and see the maintainers opinion, while documentaion the process 
and our impressions.

\subsubsection{Systematic Approach to Mitigate Code Duplication}

In C programming, communication between source files is achieved by creating header files that specify 
libraries \citep{Cbook}. Since the Linux kernel is primarily written in C, we eliminated code duplications 
by consolidating duplicated code into a single library, which would replace instances of 
duplication across the codebase.

For each duplicated function pair, for each function in the pair, we used the \textit{function information} functionality 
(described in Section \ref{subsec:functioncommand}) to locate all duplications of the function in the codebase, 
as it may have been duplicated more times then the two occurences of the duplicated function pair. 
This strategy resulted in a collection of duplicated functions and corresponding code files.

To identify shared code more effectively, we extended this approach to search for other common 
functions across all collection files. We then applied specific refactoring methods to each shared 
function. If the functions were identical across files, we removed the duplicates and created a single 
function in the library. If modifications existed, we applied case-specific refactoring.

\subsection{Research with students}

\todo[inline]{Research with students does not look good.}

Posterior of the initial participant observation that we made, we decided to expand the experiment 
by proposing to students mitigate duplication found by the tool and send patches to the kernel community.

In the Free Software Development course at University of São Paulo, ministred by the advisor 
of this work at the first semester of 2025, we have proposed to the students the possibility
of mitigating duplications in the IIO subsystem and the AMD display driver found with the Arkanjo tool.
The course had a total of X students, and of that, X students being undergraduate students
and Y begin graduate students.

On the course, the students are asked to form groups of one, two or three students and together 
make a contribution to a open source software. To auxiliate the students on this task, the 
professor and teaching assistants prepares multiple alternatives on how to contribute to open source projects, 
including simple contributions as updating documentation or code style fixes. In this context, 
we have proposed two alternatives for the students related to the tool.

For the first alternative, one of the teaching assistants used the Arkanjo tool in the IIO subsystem and
listed interesting duplicated functions pair that the groups can simple mitigate this specific duplication pair, 
and it is up to the students on how
to refactor the code to mitigate the duplications and pass through the process to send patches to the IIO 
maintainers to review. For the second alternative, we propose a similar experience then the 
participant observation method, where the students pass through the whole process of executing the Arkanjo tool
in the AMD display driver, analyze the duplications found, create a patch to mitigate a duplication and sent
the patch to the AMD display driver's maintainers.

From the students enrolled in the in the course, X opted for the first alternative and 1 opted for the second
alternative, forming Y groups working on the first alternative and 1 group working on the second alternative. 
These number represent X\% of the students choosing for approching duplications them the other contribution 
alternatives, including more simpler and easy to be done.  It is worth highlighting that none of the students
that choose to mitigate duplications had made a contribution to the Linux kernel before,
meaning that the patch to mitigate the duplication being the first tentative to contribute to the kernel as
newcomers.

The groups have been request to document the experience and approaches to refactor the duplications and the
experience of submiting a patch to the Linux kernel in blogs. We had analyzed these blogs to undertand 
patterns of refactor used for mitigating the duplications, the experience on send the patches and the 
opinions of the subsystem maintainers on the mitigations. Appendix X list the blogs and patches made by the 
student.

For the teaching assistant and the student that executed the Arkanjo tool to explore duplications, 
we have asked them to answer some questions related to the experience of using the tool and what could be
improved. The question asked can be found below and the answers can be found in Appendix Y.


